{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a96d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, matthews_corrcoef)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd38bb",
   "metadata": {},
   "source": [
    "# Split data.csv into train and test CSV files\n",
    "df_original = pd.read_csv('heart.csv')\n",
    "#https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset\n",
    "\n",
    "#df_original = df_original.drop_duplicates().reset_index(drop=True)\n",
    "df_original = df_original.fillna(df_original.median(numeric_only=True))\n",
    "\n",
    "# Separate features and target\n",
    "X_full = df_original.iloc[:, :-1]\n",
    "y_full = df_original.iloc[:, -1]\n",
    "\n",
    "# Perform 80-20 train-test split\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Combine features and target for both datasets\n",
    "train_df = pd.concat([X_train_split, y_train_split], axis=1)\n",
    "test_df = pd.concat([X_test_split, y_test_split], axis=1)\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv('train_data.csv', index=False)\n",
    "test_df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "print(f\"Original data shape: {df_original.shape}\")\n",
    "print(f\"Training data saved to 'train_data.csv': {train_df.shape[0]} rows, {train_df.shape[1]} columns\")\n",
    "print(f\"Test data saved to 'test_data.csv': {test_df.shape[0]} rows, {test_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ca721",
   "metadata": {},
   "source": [
    "age\n",
    "sex\n",
    "chest pain type (4 values)\n",
    "resting blood pressure\n",
    "serum cholestoral in mg/dl\n",
    "fasting blood sugar > 120 mg/dl\n",
    "resting electrocardiographic results (values 0,1,2)\n",
    "maximum heart rate achieved\n",
    "exercise induced angina\n",
    "oldpeak = ST depression induced by exercise relative to rest\n",
    "the slope of the peak exercise ST segment\n",
    "number of major vessels (0-3) colored by flourosopy\n",
    "thal: 0 = normal; 1 = fixed defect; 2 = reversable defect The names and social security numbers of the patients were recently removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15468128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 820\n",
      "Original features: 13\n",
      "\n",
      "Numerical columns (5): ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
      "Categorical columns (8): ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
      "\n",
      "Preprocessor fitted and saved to 'trained_models\\preprocessor.pkl'\n",
      "Processed features: 22\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "df = pd.read_csv('train_data.csv')\n",
    "\n",
    "X_train = df.iloc[:, :-1]\n",
    "y_train = df.iloc[:, -1]\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "\n",
    "# Define feature types based on data dictionary\n",
    "numerical_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "# Filter to only include columns that exist in the dataset\n",
    "numerical_cols = [col for col in numerical_cols if col in X_train.columns]\n",
    "categorical_cols = [col for col in categorical_cols if col in X_train.columns]\n",
    "\n",
    "print(f\"\\nNumerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "if len(categorical_cols) > 0:\n",
    "    # One-hot encoding for categorical features and scaling for numerical features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "        ])\n",
    "else:\n",
    "    # Only scaling if no categorical features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols)\n",
    "        ])\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Save preprocessor and models in trained_models directory\n",
    "models_dir = 'trained_models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the preprocessor for later use on test data\n",
    "preprocessor_path = os.path.join(models_dir, 'preprocessor.pkl')\n",
    "with open(preprocessor_path, 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(f\"\\nPreprocessor fitted and saved to '{preprocessor_path}'\")\n",
    "print(f\"Processed features: {X_train_processed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd817940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio: 0.94\n",
      "Logistic Regression trained successfully\n",
      "Decision Tree trained successfully\n",
      "K-Nearest Neighbors trained successfully\n",
      "Naive Bayes trained successfully\n",
      "Random Forest trained successfully\n",
      "XGBoost trained successfully\n"
     ]
    }
   ],
   "source": [
    "# Calculate imbalance ratio for XGBoost\n",
    "imbalance_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Class imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "\n",
    "# Create instances of all 6 models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=2000, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),  # KNN doesn't support class_weight\n",
    "    'Naive Bayes': GaussianNB(),  # Naive Bayes doesn't support class_weight\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=200),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss', scale_pos_weight=imbalance_ratio)\n",
    "}\n",
    "\n",
    "# Train all models on processed data\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f\"{name} trained successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8ed44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 205\n",
      "Processed test features: 22\n",
      "\n",
      "==================================================\n",
      "Model Performance Summary:\n",
      "                     Accuracy  AUC Score  Precision    Recall  F1 Score  \\\n",
      "Logistic Regression  0.819512   0.908148   0.779661  0.893204  0.832579   \n",
      "Decision Tree        0.985366   0.985437   1.000000  0.970874  0.985222   \n",
      "K-Nearest Neighbors  0.790244   0.929516   0.763158  0.844660  0.801843   \n",
      "Naive Bayes          0.804878   0.842328   0.769231  0.873786  0.818182   \n",
      "Random Forest        1.000000   1.000000   1.000000  1.000000  1.000000   \n",
      "XGBoost              0.985366   1.000000   1.000000  0.970874  0.985222   \n",
      "\n",
      "                     MCC Score  \n",
      "Logistic Regression   0.645720  \n",
      "Decision Tree         0.971151  \n",
      "K-Nearest Neighbors   0.583632  \n",
      "Naive Bayes           0.615261  \n",
      "Random Forest         1.000000  \n",
      "XGBoost               0.971151  \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load test data for evaluation\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "X_test = test_df.iloc[:, :-1]\n",
    "y_test = test_df.iloc[:, -1]\n",
    "\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Apply the same preprocessing to test data\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Processed test features: {X_test_processed.shape[1]}\")\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Make predictions on processed test data\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_pred_proba = model.predict_proba(X_test_processed)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'AUC Score': auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'MCC Score': mcc\n",
    "    }\n",
    "\n",
    "# Create a summary dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Performance Summary:\")\n",
    "print(results_df)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbcc33fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models to trained_models directory...\n",
      "\n",
      "Saved Logistic Regression to trained_models\\logistic_regression.pkl\n",
      "Saved Decision Tree to trained_models\\decision_tree.pkl\n",
      "Saved K-Nearest Neighbors to trained_models\\k-nearest_neighbors.pkl\n",
      "Saved Naive Bayes to trained_models\\naive_bayes.pkl\n",
      "Saved Random Forest to trained_models\\random_forest.pkl\n",
      "Saved XGBoost to trained_models\\xgboost.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the models with feature engineering\n",
    "print(\"Saving models to trained_models directory...\\n\")\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Create safe filename\n",
    "    filename = name.replace(' ', '_').lower() + '.pkl'\n",
    "    filepath = os.path.join(models_dir, filename)\n",
    "    \n",
    "    # Save model\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"Saved {name} to {filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
